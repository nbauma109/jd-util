name: LLM Suggestions PR (Local)

on:
  workflow_dispatch:
    inputs:
      user_prompt:
        description: "Prompt for the LLM (e.g., add docstrings, improve TS types, small perf fixes)"
        required: false
        type: string
      model:
        description: "Ollama model tag"
        required: false
        default: "llama3.2:3b"
        type: string
      base_branch:
        description: "Base branch for the suggestions PR (defaults to repo default branch)"
        required: false
        type: string
      max_files:
        description: "Max files to consider"
        required: false
        default: "50"
        type: string
      max_file_kb:
        description: "Max size per file (KB)"
        required: false
        default: "120"
        type: string
      max_total_kb:
        description: "Overall context budget (KB)"
        required: false
        default: "800"
        type: string
  schedule:
    # Runs daily at 05:30 UTC
    - cron: "30 5 * * *"

permissions:
  contents: write
  pull-requests: write

jobs:
  suggest:
    runs-on: ubuntu-latest
    env:
      # Inputs have defaults above; no need for "||" expressions that can confuse YAML.
      LLM_MODEL: ${{ inputs.model }}
      MAX_FILES: ${{ inputs.max_files }}
      MAX_FILE_KB: ${{ inputs.max_file_kb }}
      MAX_TOTAL_KB: ${{ inputs.max_total_kb }}
      COMMIT_MESSAGE: "chore(llm): apply local LLM suggestions"
      PR_TITLE_PREFIX: "LLM suggestions"
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Resolve base branch
        id: base
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${{ inputs.base_branch }}" ]; then
            base="${{ inputs.base_branch }}"
          else
            base="$(git remote show origin | sed -n '/HEAD branch/s/.*: //p')"
            base="${base:-main}"
          fi
          echo "base=${base}" >> "$GITHUB_OUTPUT"
          echo "Using base branch: ${base}"

      - name: Install tools
        run: |
          sudo apt-get update
          sudo apt-get install -y jq patch
          python -m pip install --upgrade pip
          pip install requests

      - name: Start Ollama (local)
        uses: ollama/ollama-action@v1

      - name: Pull local model
        run: |
          echo "Pulling model: ${LLM_MODEL}"
          ollama pull "${LLM_MODEL}"

      - name: Prepare prompt and file list
        id: prep
        env:
          USER_PROMPT: ${{ inputs.user_prompt }}
          BASE_BRANCH: ${{ steps.base.outputs.base }}
          MAX_FILES: ${{ env.MAX_FILES }}
          MAX_FILE_KB: ${{ env.MAX_FILE_KB }}
          MAX_TOTAL_KB: ${{ env.MAX_TOTAL_KB }}
        run: |
          bash .github/scripts/llm_prep.sh
          echo "files_count=$(wc -l < .llm_files.txt | tr -d ' ')" >> "$GITHUB_OUTPUT"

      - name: Generate diff with local LLM
        id: gen
        env:
          LLM_MODEL: ${{ env.LLM_MODEL }}
        run: |
          python .github/scripts/llm_generate.py

      - name: Validate, apply, commit, and open PR
        id: apply
        env:
          LLM_MODEL: ${{ env.LLM_MODEL }}
          BASE_BRANCH: ${{ steps.base.outputs.base }}
          COMMIT_MESSAGE: ${{ env.COMMIT_MESSAGE }}
          PR_TITLE_PREFIX: ${{ env.PR_TITLE_PREFIX }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          bash .github/scripts/llm_validate_apply.sh

      - name: No-op note
        if: steps.apply.outputs.no_changes == 'true'
        run: echo "No changes suggested by the model this run."
